// Code generated by llmango CLI. DO NOT EDIT.
package mango

import (
	"encoding/json"
	"log"

	"github.com/llmang/llmango/llmango"
	"github.com/llmang/llmango/llmangoagents"
	"github.com/llmang/llmango/openrouter"
)

// Config-generated goals and prompts

// sentimentAnalysisGoal is generated from configuration
var sentimentAnalysisGoal = llmango.Goal{
	UID:         "sentiment-analysis",
	Title:       "Sentiment Analysis",
	Description: "Analyzes the sentiment of text input",
	InputExample:  json.RawMessage(`{"text":"I absolutely love this new AI system! It's incredibly helpful and makes my work so much easier."}`),
	OutputExample: json.RawMessage(`{"confidence":0.95,"reasoning":"Contains positive language like 'love', 'incredibly helpful', and 'easier'","sentiment":"positive"}`),
}

// textSummaryGoal is generated from configuration
var textSummaryGoal = llmango.Goal{
	UID:         "text-summary",
	Title:       "Text Summary",
	Description: "Summarizes long text into key points",
	InputExample:  json.RawMessage(`{"text":"Artificial intelligence (AI) is transforming industries worldwide. From healthcare to finance, AI systems are automating complex tasks, improving efficiency, and enabling new capabilities. Machine learning algorithms can now process vast amounts of data to identify patterns and make predictions. However, the rapid advancement of AI also raises important questions about ethics, job displacement, and the need for proper regulation. As we move forward, it's crucial to balance innovation with responsible development to ensure AI benefits society as a whole."}`),
	OutputExample: json.RawMessage(`{"key_points":["AI systems are automating complex tasks across industries","Machine learning processes data to identify patterns and make predictions","Rapid AI advancement raises ethics and job displacement concerns","Need for proper regulation and responsible development"],"summary":"AI is transforming industries by automating tasks and improving efficiency, but raises important questions about ethics and regulation that need to be addressed.","word_count":150}`),
}

// emailClassificationGoal is generated from configuration
var emailClassificationGoal = llmango.Goal{
	UID:         "email-classification",
	Title:       "Email Classification",
	Description: "Classifies emails into categories like spam, important, promotional",
	InputExample:  json.RawMessage(`{"body":"Don't miss out on our biggest sale of the year! Click here to shop now.","sender":"sales@example.com","subject":"Limited Time Offer - 50% Off Everything!"}`),
	OutputExample: json.RawMessage(`{"category":"promotional","confidence":0.92,"reasoning":"Contains promotional language and discount offers"}`),
}

// languageDetectionGoal is generated from configuration
var languageDetectionGoal = llmango.Goal{
	UID:         "language-detection",
	Title:       "Language Detection",
	Description: "Detects the language of input text",
	InputExample:  json.RawMessage(`{"text":"Bonjour, comment allez-vous aujourd'hui?"}`),
	OutputExample: json.RawMessage(`{"confidence":0.98,"language":"French","language_code":"fr"}`),
}

// sentimentUniversalPrompt is generated from configuration
var sentimentUniversalPrompt = llmango.Prompt{
	UID:      "sentiment-universal",
	GoalUID:  "sentiment-analysis",
	Model:    "anthropic/claude-3-sonnet",
	Weight:   100,
	IsCanary: false,
	MaxRuns:  0,
	Messages: []openrouter.Message{
		{Role: "system", Content: "You are a sentiment analysis expert. Analyze the sentiment of the given text and provide a confidence score."},
		{Role: "user", Content: "Analyze the sentiment of this text: {{text}}"},
	},
}

// summaryUniversalPrompt is generated from configuration
var summaryUniversalPrompt = llmango.Prompt{
	UID:      "summary-universal",
	GoalUID:  "text-summary",
	Model:    "meta-llama/llama-3.1-405b-instruct",
	Weight:   100,
	IsCanary: false,
	MaxRuns:  0,
	Messages: []openrouter.Message{
		{Role: "system", Content: "You are a text summarization expert. Create concise summaries with key points."},
		{Role: "user", Content: "Summarize this text: {{text}}"},
	},
}

// sentimentStructuredPrompt is generated from configuration
var sentimentStructuredPrompt = llmango.Prompt{
	UID:      "sentiment-structured",
	GoalUID:  "sentiment-analysis",
	Model:    "openai/gpt-4",
	Weight:   100,
	IsCanary: false,
	MaxRuns:  0,
	Messages: []openrouter.Message{
		{Role: "system", Content: "You are a sentiment analysis expert. Analyze the sentiment of the given text and provide a confidence score."},
		{Role: "user", Content: "Analyze the sentiment of this text: {{text}}"},
	},
}

// summaryStructuredPrompt is generated from configuration
var summaryStructuredPrompt = llmango.Prompt{
	UID:      "summary-structured",
	GoalUID:  "text-summary",
	Model:    "openai/gpt-3.5-turbo",
	Weight:   100,
	IsCanary: false,
	MaxRuns:  0,
	Messages: []openrouter.Message{
		{Role: "system", Content: "You are a text summarization expert. Create concise summaries with key points."},
		{Role: "user", Content: "Summarize this text: {{text}}"},
	},
}

// emailClassificationOpenaiPrompt is generated from configuration
var emailClassificationOpenaiPrompt = llmango.Prompt{
	UID:      "email-classification-openai",
	GoalUID:  "email-classification",
	Model:    "openai/gpt-4",
	Weight:   100,
	IsCanary: false,
	MaxRuns:  0,
	Messages: []openrouter.Message{
		{Role: "system", Content: "You are an email classification expert. Classify emails into categories: spam, important, promotional, personal, work."},
		{Role: "user", Content: "Classify this email:\nSubject: {{subject}}\nFrom: {{sender}}\nBody: {{body}}"},
	},
}

// emailClassificationClaudePrompt is generated from configuration
var emailClassificationClaudePrompt = llmango.Prompt{
	UID:      "email-classification-claude",
	GoalUID:  "email-classification",
	Model:    "anthropic/claude-3-sonnet",
	Weight:   100,
	IsCanary: false,
	MaxRuns:  0,
	Messages: []openrouter.Message{
		{Role: "system", Content: "You are an email classification expert. Classify emails into categories: spam, important, promotional, personal, work."},
		{Role: "user", Content: "Classify this email:\nSubject: {{subject}}\nFrom: {{sender}}\nBody: {{body}}"},
	},
}

// languageDetectionOpenaiPrompt is generated from configuration
var languageDetectionOpenaiPrompt = llmango.Prompt{
	UID:      "language-detection-openai",
	GoalUID:  "language-detection",
	Model:    "openai/gpt-3.5-turbo",
	Weight:   100,
	IsCanary: false,
	MaxRuns:  0,
	Messages: []openrouter.Message{
		{Role: "system", Content: "You are a language detection expert. Identify the language of the given text and provide the language name and ISO code."},
		{Role: "user", Content: "What language is this text: {{text}}"},
	},
}

// languageDetectionLlamaPrompt is generated from configuration
var languageDetectionLlamaPrompt = llmango.Prompt{
	UID:      "language-detection-llama",
	GoalUID:  "language-detection",
	Model:    "meta-llama/llama-3.1-405b-instruct",
	Weight:   100,
	IsCanary: false,
	MaxRuns:  0,
	Messages: []openrouter.Message{
		{Role: "system", Content: "You are a language detection expert. Identify the language of the given text and provide the language name and ISO code."},
		{Role: "user", Content: "What language is this text: {{text}}"},
	},
}

type Mango struct {
	*llmango.LLMangoManager
	AgentSystem *llmangoagents.AgentSystemManager
	Debug       bool
}

func CreateMango(or *openrouter.OpenRouter) (*Mango, error) {
	llmangoManager, err := llmango.CreateLLMangoManger(or)
	if err != nil {
		log.Fatalf("failed to setup llmango manager: %v", err)
	}

	// Initialize goals
	llmangoManager.AddGoals(
		&sentimentAnalysisGoal,
		&textSummaryGoal,
		&emailClassificationGoal,
		&languageDetectionGoal,
	)

	// Initialize prompts
	llmangoManager.AddPrompts(
		&sentimentUniversalPrompt,
		&summaryUniversalPrompt,
		&sentimentStructuredPrompt,
		&summaryStructuredPrompt,
		&emailClassificationOpenaiPrompt,
		&emailClassificationClaudePrompt,
		&languageDetectionOpenaiPrompt,
		&languageDetectionLlamaPrompt,
	)

	return &Mango{
		LLMangoManager: llmangoManager,
		Debug:          false, // Can be enabled by calling SetDebug(true)
	}, nil
}

// SetDebug enables or disables debug logging for requests and responses
func (m *Mango) SetDebug(enabled bool) {
	m.Debug = enabled
}

// debugLog logs debug information if debug mode is enabled
func (m *Mango) debugLog(format string, args ...interface{}) {
	if m.Debug {
		log.Printf("[MANGO DEBUG] "+format, args...)
	}
}


// SentimentAnalysis executes the Sentiment Analysis goal
func (m *Mango) SentimentAnalysis(input *SentimentInput) (*SentimentOutput, error) {
	if m.Debug {
		m.debugLog("=== SentimentAnalysis Request ===")
		inputJSON, _ := json.MarshalIndent(input, "", "  ")
		m.debugLog("Input: %s", string(inputJSON))
		
		// Log goal schema information
		m.debugLog("Goal: %s (%s)", "sentiment-analysis", "Sentiment Analysis")
		m.debugLog("Input Schema: %s", string(sentimentAnalysisGoal.InputExample))
		m.debugLog("Output Schema: %s", string(sentimentAnalysisGoal.OutputExample))
	}
	
	result, rawResponse, err := llmango.RunRaw[SentimentInput, SentimentOutput](m.LLMangoManager, &sentimentAnalysisGoal, input)
	
	if m.Debug {
		if err != nil {
			m.debugLog("Error: %v", err)
		} else {
			// Log the raw response details
			m.debugLog("Model Used: %s", rawResponse.Model)
			m.debugLog("Usage - Prompt Tokens: %d, Completion Tokens: %d, Total: %d",
				rawResponse.Usage.PromptTokens, rawResponse.Usage.CompletionTokens, rawResponse.Usage.TotalTokens)
			
			// Log the response
			resultJSON, _ := json.MarshalIndent(result, "", "  ")
			m.debugLog("Response: %s", string(resultJSON))
			
			// Log raw response if available
			if len(rawResponse.Choices) > 0 {
				m.debugLog("Raw Response Content: %s", rawResponse.Choices[0].Message.Content)
			}
		}
		m.debugLog("=== SentimentAnalysis Complete ===")
	}
	
	return result, err
}

// SentimentAnalysisRaw executes the Sentiment Analysis goal and returns the raw OpenRouter response
func (m *Mango) SentimentAnalysisRaw(input *SentimentInput) (*SentimentOutput, *openrouter.NonStreamingChatResponse, error) {
	return llmango.RunRaw[SentimentInput, SentimentOutput](m.LLMangoManager, &sentimentAnalysisGoal, input)
}

// TextSummary executes the Text Summary goal
func (m *Mango) TextSummary(input *SummaryInput) (*SummaryOutput, error) {
	if m.Debug {
		m.debugLog("=== TextSummary Request ===")
		inputJSON, _ := json.MarshalIndent(input, "", "  ")
		m.debugLog("Input: %s", string(inputJSON))
		
		// Log goal schema information
		m.debugLog("Goal: %s (%s)", "text-summary", "Text Summary")
		m.debugLog("Input Schema: %s", string(textSummaryGoal.InputExample))
		m.debugLog("Output Schema: %s", string(textSummaryGoal.OutputExample))
	}
	
	result, rawResponse, err := llmango.RunRaw[SummaryInput, SummaryOutput](m.LLMangoManager, &textSummaryGoal, input)
	
	if m.Debug {
		if err != nil {
			m.debugLog("Error: %v", err)
		} else {
			// Log the raw response details
			m.debugLog("Model Used: %s", rawResponse.Model)
			m.debugLog("Usage - Prompt Tokens: %d, Completion Tokens: %d, Total: %d",
				rawResponse.Usage.PromptTokens, rawResponse.Usage.CompletionTokens, rawResponse.Usage.TotalTokens)
			
			// Log the response
			resultJSON, _ := json.MarshalIndent(result, "", "  ")
			m.debugLog("Response: %s", string(resultJSON))
			
			// Log raw response if available
			if len(rawResponse.Choices) > 0 {
				m.debugLog("Raw Response Content: %s", rawResponse.Choices[0].Message.Content)
			}
		}
		m.debugLog("=== TextSummary Complete ===")
	}
	
	return result, err
}

// TextSummaryRaw executes the Text Summary goal and returns the raw OpenRouter response
func (m *Mango) TextSummaryRaw(input *SummaryInput) (*SummaryOutput, *openrouter.NonStreamingChatResponse, error) {
	return llmango.RunRaw[SummaryInput, SummaryOutput](m.LLMangoManager, &textSummaryGoal, input)
}

// EmailClassification executes the Email Classification goal
func (m *Mango) EmailClassification(input *EmailInput) (*EmailOutput, error) {
	if m.Debug {
		m.debugLog("=== EmailClassification Request ===")
		inputJSON, _ := json.MarshalIndent(input, "", "  ")
		m.debugLog("Input: %s", string(inputJSON))
		
		// Log goal schema information
		m.debugLog("Goal: %s (%s)", "email-classification", "Email Classification")
		m.debugLog("Input Schema: %s", string(emailClassificationGoal.InputExample))
		m.debugLog("Output Schema: %s", string(emailClassificationGoal.OutputExample))
	}
	
	result, rawResponse, err := llmango.RunRaw[EmailInput, EmailOutput](m.LLMangoManager, &emailClassificationGoal, input)
	
	if m.Debug {
		if err != nil {
			m.debugLog("Error: %v", err)
		} else {
			// Log the raw response details
			m.debugLog("Model Used: %s", rawResponse.Model)
			m.debugLog("Usage - Prompt Tokens: %d, Completion Tokens: %d, Total: %d",
				rawResponse.Usage.PromptTokens, rawResponse.Usage.CompletionTokens, rawResponse.Usage.TotalTokens)
			
			// Log the response
			resultJSON, _ := json.MarshalIndent(result, "", "  ")
			m.debugLog("Response: %s", string(resultJSON))
			
			// Log raw response if available
			if len(rawResponse.Choices) > 0 {
				m.debugLog("Raw Response Content: %s", rawResponse.Choices[0].Message.Content)
			}
		}
		m.debugLog("=== EmailClassification Complete ===")
	}
	
	return result, err
}

// EmailClassificationRaw executes the Email Classification goal and returns the raw OpenRouter response
func (m *Mango) EmailClassificationRaw(input *EmailInput) (*EmailOutput, *openrouter.NonStreamingChatResponse, error) {
	return llmango.RunRaw[EmailInput, EmailOutput](m.LLMangoManager, &emailClassificationGoal, input)
}

// LanguageDetection executes the Language Detection goal
func (m *Mango) LanguageDetection(input *LanguageInput) (*LanguageOutput, error) {
	if m.Debug {
		m.debugLog("=== LanguageDetection Request ===")
		inputJSON, _ := json.MarshalIndent(input, "", "  ")
		m.debugLog("Input: %s", string(inputJSON))
		
		// Log goal schema information
		m.debugLog("Goal: %s (%s)", "language-detection", "Language Detection")
		m.debugLog("Input Schema: %s", string(languageDetectionGoal.InputExample))
		m.debugLog("Output Schema: %s", string(languageDetectionGoal.OutputExample))
	}
	
	result, rawResponse, err := llmango.RunRaw[LanguageInput, LanguageOutput](m.LLMangoManager, &languageDetectionGoal, input)
	
	if m.Debug {
		if err != nil {
			m.debugLog("Error: %v", err)
		} else {
			// Log the raw response details
			m.debugLog("Model Used: %s", rawResponse.Model)
			m.debugLog("Usage - Prompt Tokens: %d, Completion Tokens: %d, Total: %d",
				rawResponse.Usage.PromptTokens, rawResponse.Usage.CompletionTokens, rawResponse.Usage.TotalTokens)
			
			// Log the response
			resultJSON, _ := json.MarshalIndent(result, "", "  ")
			m.debugLog("Response: %s", string(resultJSON))
			
			// Log raw response if available
			if len(rawResponse.Choices) > 0 {
				m.debugLog("Raw Response Content: %s", rawResponse.Choices[0].Message.Content)
			}
		}
		m.debugLog("=== LanguageDetection Complete ===")
	}
	
	return result, err
}

// LanguageDetectionRaw executes the Language Detection goal and returns the raw OpenRouter response
func (m *Mango) LanguageDetectionRaw(input *LanguageInput) (*LanguageOutput, *openrouter.NonStreamingChatResponse, error) {
	return llmango.RunRaw[LanguageInput, LanguageOutput](m.LLMangoManager, &languageDetectionGoal, input)
}
