// Code generated by llmango CLI. DO NOT EDIT.
package mango

import (
	"encoding/json"
	"log"

	"github.com/llmang/llmango/llmango"
	"github.com/llmang/llmango/openrouter"
)

// Config-generated goals and prompts

// emailClassificationGoal is generated from configuration
var emailClassificationGoal = llmango.Goal{
	UID:         "email-classification",
	Title:       "Email Classification",
	Description: "Classifies emails into categories like spam, important, promotional",
	InputExample:  json.RawMessage(`{"body":"Don't miss out on our biggest sale of the year! Click here to shop now.","sender":"sales@example.com","subject":"Limited Time Offer - 50% Off Everything!"}`),
	OutputExample: json.RawMessage(`{"category":"promotional","confidence":0.92,"reasoning":"Contains promotional language and discount offers"}`),
}

// languageDetectionGoal is generated from configuration
var languageDetectionGoal = llmango.Goal{
	UID:         "language-detection",
	Title:       "Language Detection",
	Description: "Detects the language of input text",
	InputExample:  json.RawMessage(`{"text":"Bonjour, comment allez-vous aujourd'hui?"}`),
	OutputExample: json.RawMessage(`{"confidence":0.98,"language":"French","language_code":"fr"}`),
}

// textSummaryOpenaiPrompt is generated from configuration
var textSummaryOpenaiPrompt = llmango.Prompt{
	UID:      "text-summary-openai",
	GoalUID:  "text-summary",
	Model:    "openai/gpt-4",
	Weight:   100,
	IsCanary: false,
	MaxRuns:  0,
	Messages: []openrouter.Message{
		{Role: "system", Content: "You are a text summarization expert. Create concise summaries with key points and word counts."},
		{Role: "user", Content: "Summarize this text and extract key points: {{text}}"},
	},
}

// emailClassificationOpenaiPrompt is generated from configuration
var emailClassificationOpenaiPrompt = llmango.Prompt{
	UID:      "email-classification-openai",
	GoalUID:  "email-classification",
	Model:    "openai/gpt-4",
	Weight:   100,
	IsCanary: false,
	MaxRuns:  0,
	Messages: []openrouter.Message{
		{Role: "system", Content: "You are an email classification expert. Classify emails into categories: spam, important, promotional, personal, work."},
		{Role: "user", Content: "Classify this email:\nSubject: {{subject}}\nFrom: {{sender}}\nBody: {{body}}"},
	},
}

// emailClassificationClaudePrompt is generated from configuration
var emailClassificationClaudePrompt = llmango.Prompt{
	UID:      "email-classification-claude",
	GoalUID:  "email-classification",
	Model:    "anthropic/claude-3-sonnet",
	Weight:   100,
	IsCanary: false,
	MaxRuns:  0,
	Messages: []openrouter.Message{
		{Role: "system", Content: "You are an email classification expert. Classify emails into categories: spam, important, promotional, personal, work."},
		{Role: "user", Content: "Classify this email:\nSubject: {{subject}}\nFrom: {{sender}}\nBody: {{body}}"},
	},
}

// languageDetectionOpenaiPrompt is generated from configuration
var languageDetectionOpenaiPrompt = llmango.Prompt{
	UID:      "language-detection-openai",
	GoalUID:  "language-detection",
	Model:    "openai/gpt-3.5-turbo",
	Weight:   100,
	IsCanary: false,
	MaxRuns:  0,
	Messages: []openrouter.Message{
		{Role: "system", Content: "You are a language detection expert. Identify the language of the given text and provide the language name and ISO code."},
		{Role: "user", Content: "What language is this text: {{text}}"},
	},
}

// sentimentUniversalPrompt is generated from configuration
var sentimentUniversalPrompt = llmango.Prompt{
	UID:      "sentiment-universal",
	GoalUID:  "sentiment-analysis",
	Model:    "anthropic/claude-3-sonnet",
	Weight:   100,
	IsCanary: false,
	MaxRuns:  0,
	Messages: []openrouter.Message{
		{Role: "system", Content: "You are a sentiment analysis expert. Analyze the sentiment of the given text and provide a confidence score."},
		{Role: "user", Content: "Analyze the sentiment of this text: {{text}}"},
	},
}

// sentimentOpenaiPrompt is generated from configuration
var sentimentOpenaiPrompt = llmango.Prompt{
	UID:      "sentiment-openai",
	GoalUID:  "sentiment-analysis",
	Model:    "openai/gpt-4",
	Weight:   100,
	IsCanary: false,
	MaxRuns:  0,
	Messages: []openrouter.Message{
		{Role: "system", Content: "You are a sentiment analysis expert. Analyze the sentiment of the given text and provide a confidence score."},
		{Role: "user", Content: "Analyze the sentiment of this text: {{text}}"},
	},
}

// codeReviewClaudePrompt is generated from configuration
var codeReviewClaudePrompt = llmango.Prompt{
	UID:      "code-review-claude",
	GoalUID:  "code-review",
	Model:    "anthropic/claude-3-sonnet",
	Weight:   100,
	IsCanary: false,
	MaxRuns:  0,
	Messages: []openrouter.Message{
		{Role: "system", Content: "You are a code review expert. Analyze code and provide suggestions for improvement."},
		{Role: "user", Content: "Review this {{language}} code: {{code}}"},
	},
}

// translationOpenaiPrompt is generated from configuration
var translationOpenaiPrompt = llmango.Prompt{
	UID:      "translation-openai",
	GoalUID:  "translation",
	Model:    "openai/gpt-4",
	Weight:   100,
	IsCanary: false,
	MaxRuns:  0,
	Messages: []openrouter.Message{
		{Role: "system", Content: "You are a translation expert. Translate text accurately between languages."},
		{Role: "user", Content: "Translate this text to {{target_lang}}: {{text}}"},
	},
}

// languageDetectionLlamaPrompt is generated from configuration
var languageDetectionLlamaPrompt = llmango.Prompt{
	UID:      "language-detection-llama",
	GoalUID:  "language-detection",
	Model:    "meta-llama/llama-3.1-405b-instruct",
	Weight:   100,
	IsCanary: false,
	MaxRuns:  0,
	Messages: []openrouter.Message{
		{Role: "system", Content: "You are a language detection expert. Identify the language of the given text and provide the language name and ISO code."},
		{Role: "user", Content: "What language is this text: {{text}}"},
	},
}

// summaryUniversalPrompt is generated from configuration
var summaryUniversalPrompt = llmango.Prompt{
	UID:      "summary-universal",
	GoalUID:  "text-summary",
	Model:    "meta-llama/llama-3.1-405b-instruct",
	Weight:   100,
	IsCanary: false,
	MaxRuns:  0,
	Messages: []openrouter.Message{
		{Role: "system", Content: "You are a text summarization expert. Create concise summaries with key points."},
		{Role: "user", Content: "Summarize this text: {{text}}"},
	},
}

type Mango struct {
	*llmango.LLMangoManager
	Debug bool
}

func CreateMango(or *openrouter.OpenRouter) (*Mango, error) {
	llmangoManager, err := llmango.CreateLLMangoManger(or)
	if err != nil {
		log.Fatalf("failed to setup llmango manager: %v", err)
	}

	// Initialize goals
	llmangoManager.AddGoals(
		&emailClassificationGoal,
		&languageDetectionGoal,
		sentimentGoal,
		codeReviewGoal,
		translationGoal,
		summaryGoal,
	)

	// Initialize prompts
	llmangoManager.AddPrompts(
		&textSummaryOpenaiPrompt,
		&emailClassificationOpenaiPrompt,
		&emailClassificationClaudePrompt,
		&languageDetectionOpenaiPrompt,
		&sentimentUniversalPrompt,
		&sentimentOpenaiPrompt,
		&codeReviewClaudePrompt,
		&translationOpenaiPrompt,
		&languageDetectionLlamaPrompt,
		&summaryUniversalPrompt,
	)

	return &Mango{
		LLMangoManager: llmangoManager,
		Debug:          false, // Can be enabled by calling SetDebug(true)
	}, nil
}

// SetDebug enables or disables debug logging for requests and responses
func (m *Mango) SetDebug(enabled bool) {
	m.Debug = enabled
}

// debugLog logs debug information if debug mode is enabled
func (m *Mango) debugLog(format string, args ...interface{}) {
	if m.Debug {
		log.Printf("[MANGO DEBUG] "+format, args...)
	}
}


// EmailClassification executes the Email Classification goal
func (m *Mango) EmailClassification(input *EmailInput) (*EmailOutput, error) {
	if m.Debug {
		m.debugLog("=== EmailClassification Request ===")
		inputJSON, _ := json.MarshalIndent(input, "", "  ")
		m.debugLog("Input: %s", string(inputJSON))
		
		// Log goal schema information
		m.debugLog("Goal: %s (%s)", "email-classification", "Email Classification")
		m.debugLog("Input Schema: %s", string(emailClassificationGoal.InputExample))
		m.debugLog("Output Schema: %s", string(emailClassificationGoal.OutputExample))
	}
	result, rawResponse, err := llmango.RunRaw[EmailInput, EmailOutput](m.LLMangoManager, &emailClassificationGoal, input)
	
	if m.Debug {
		if err != nil {
			m.debugLog("Error: %v", err)
		} else {
			// Log the raw response details
			m.debugLog("Model Used: %s", rawResponse.Model)
			m.debugLog("Usage - Prompt Tokens: %d, Completion Tokens: %d, Total: %d",
				rawResponse.Usage.PromptTokens, rawResponse.Usage.CompletionTokens, rawResponse.Usage.TotalTokens)
			
			// Log the response
			resultJSON, _ := json.MarshalIndent(result, "", "  ")
			m.debugLog("Response: %s", string(resultJSON))
			
			// Log raw response if available
			if len(rawResponse.Choices) > 0 {
				m.debugLog("Raw Response Content: %s", rawResponse.Choices[0].Message.Content)
			}
		}
		m.debugLog("=== EmailClassification Complete ===")
	}
	
	return result, err
}

// EmailClassificationRaw executes the Email Classification goal and returns the raw OpenRouter response
func (m *Mango) EmailClassificationRaw(input *EmailInput) (*EmailOutput, *openrouter.NonStreamingChatResponse, error) {
	return llmango.RunRaw[EmailInput, EmailOutput](m.LLMangoManager, &emailClassificationGoal, input)
}

// LanguageDetection executes the Language Detection goal
func (m *Mango) LanguageDetection(input *LanguageInput) (*LanguageOutput, error) {
	if m.Debug {
		m.debugLog("=== LanguageDetection Request ===")
		inputJSON, _ := json.MarshalIndent(input, "", "  ")
		m.debugLog("Input: %s", string(inputJSON))
		
		// Log goal schema information
		m.debugLog("Goal: %s (%s)", "language-detection", "Language Detection")
		m.debugLog("Input Schema: %s", string(languageDetectionGoal.InputExample))
		m.debugLog("Output Schema: %s", string(languageDetectionGoal.OutputExample))
	}
	result, rawResponse, err := llmango.RunRaw[LanguageInput, LanguageOutput](m.LLMangoManager, &languageDetectionGoal, input)
	
	if m.Debug {
		if err != nil {
			m.debugLog("Error: %v", err)
		} else {
			// Log the raw response details
			m.debugLog("Model Used: %s", rawResponse.Model)
			m.debugLog("Usage - Prompt Tokens: %d, Completion Tokens: %d, Total: %d",
				rawResponse.Usage.PromptTokens, rawResponse.Usage.CompletionTokens, rawResponse.Usage.TotalTokens)
			
			// Log the response
			resultJSON, _ := json.MarshalIndent(result, "", "  ")
			m.debugLog("Response: %s", string(resultJSON))
			
			// Log raw response if available
			if len(rawResponse.Choices) > 0 {
				m.debugLog("Raw Response Content: %s", rawResponse.Choices[0].Message.Content)
			}
		}
		m.debugLog("=== LanguageDetection Complete ===")
	}
	
	return result, err
}

// LanguageDetectionRaw executes the Language Detection goal and returns the raw OpenRouter response
func (m *Mango) LanguageDetectionRaw(input *LanguageInput) (*LanguageOutput, *openrouter.NonStreamingChatResponse, error) {
	return llmango.RunRaw[LanguageInput, LanguageOutput](m.LLMangoManager, &languageDetectionGoal, input)
}

// SentimentAnalysis executes the Sentiment Analysis goal
func (m *Mango) SentimentAnalysis(input *SentimentInput) (*SentimentOutput, error) {
	if m.Debug {
		m.debugLog("=== SentimentAnalysis Request ===")
		inputJSON, _ := json.MarshalIndent(input, "", "  ")
		m.debugLog("Input: %s", string(inputJSON))
		
		// Log goal schema information
		m.debugLog("Goal: %s (%s)", "sentiment-analysis", "Sentiment Analysis")
		m.debugLog("Input Schema: %s", string(sentimentGoal.InputExample))
		m.debugLog("Output Schema: %s", string(sentimentGoal.OutputExample))
	}
	result, rawResponse, err := llmango.RunRaw[SentimentInput, SentimentOutput](m.LLMangoManager, sentimentGoal, input)
	
	if m.Debug {
		if err != nil {
			m.debugLog("Error: %v", err)
		} else {
			// Log the raw response details
			m.debugLog("Model Used: %s", rawResponse.Model)
			m.debugLog("Usage - Prompt Tokens: %d, Completion Tokens: %d, Total: %d",
				rawResponse.Usage.PromptTokens, rawResponse.Usage.CompletionTokens, rawResponse.Usage.TotalTokens)
			
			// Log the response
			resultJSON, _ := json.MarshalIndent(result, "", "  ")
			m.debugLog("Response: %s", string(resultJSON))
			
			// Log raw response if available
			if len(rawResponse.Choices) > 0 {
				m.debugLog("Raw Response Content: %s", rawResponse.Choices[0].Message.Content)
			}
		}
		m.debugLog("=== SentimentAnalysis Complete ===")
	}
	
	return result, err
}

// SentimentAnalysisRaw executes the Sentiment Analysis goal and returns the raw OpenRouter response
func (m *Mango) SentimentAnalysisRaw(input *SentimentInput) (*SentimentOutput, *openrouter.NonStreamingChatResponse, error) {
	return llmango.RunRaw[SentimentInput, SentimentOutput](m.LLMangoManager, sentimentGoal, input)
}

// CodeReview executes the Code Review goal
func (m *Mango) CodeReview(input *CodeReviewInput) (*CodeReviewOutput, error) {
	if m.Debug {
		m.debugLog("=== CodeReview Request ===")
		inputJSON, _ := json.MarshalIndent(input, "", "  ")
		m.debugLog("Input: %s", string(inputJSON))
		
		// Log goal schema information
		m.debugLog("Goal: %s (%s)", "code-review", "Code Review")
		m.debugLog("Input Schema: %s", string(codeReviewGoal.InputExample))
		m.debugLog("Output Schema: %s", string(codeReviewGoal.OutputExample))
	}
	result, rawResponse, err := llmango.RunRaw[CodeReviewInput, CodeReviewOutput](m.LLMangoManager, codeReviewGoal, input)
	
	if m.Debug {
		if err != nil {
			m.debugLog("Error: %v", err)
		} else {
			// Log the raw response details
			m.debugLog("Model Used: %s", rawResponse.Model)
			m.debugLog("Usage - Prompt Tokens: %d, Completion Tokens: %d, Total: %d",
				rawResponse.Usage.PromptTokens, rawResponse.Usage.CompletionTokens, rawResponse.Usage.TotalTokens)
			
			// Log the response
			resultJSON, _ := json.MarshalIndent(result, "", "  ")
			m.debugLog("Response: %s", string(resultJSON))
			
			// Log raw response if available
			if len(rawResponse.Choices) > 0 {
				m.debugLog("Raw Response Content: %s", rawResponse.Choices[0].Message.Content)
			}
		}
		m.debugLog("=== CodeReview Complete ===")
	}
	
	return result, err
}

// CodeReviewRaw executes the Code Review goal and returns the raw OpenRouter response
func (m *Mango) CodeReviewRaw(input *CodeReviewInput) (*CodeReviewOutput, *openrouter.NonStreamingChatResponse, error) {
	return llmango.RunRaw[CodeReviewInput, CodeReviewOutput](m.LLMangoManager, codeReviewGoal, input)
}

// Translation executes the Translation goal
func (m *Mango) Translation(input *TranslationInput) (*TranslationOutput, error) {
	if m.Debug {
		m.debugLog("=== Translation Request ===")
		inputJSON, _ := json.MarshalIndent(input, "", "  ")
		m.debugLog("Input: %s", string(inputJSON))
		
		// Log goal schema information
		m.debugLog("Goal: %s (%s)", "translation", "Translation")
		m.debugLog("Input Schema: %s", string(translationGoal.InputExample))
		m.debugLog("Output Schema: %s", string(translationGoal.OutputExample))
	}
	result, rawResponse, err := llmango.RunRaw[TranslationInput, TranslationOutput](m.LLMangoManager, translationGoal, input)
	
	if m.Debug {
		if err != nil {
			m.debugLog("Error: %v", err)
		} else {
			// Log the raw response details
			m.debugLog("Model Used: %s", rawResponse.Model)
			m.debugLog("Usage - Prompt Tokens: %d, Completion Tokens: %d, Total: %d",
				rawResponse.Usage.PromptTokens, rawResponse.Usage.CompletionTokens, rawResponse.Usage.TotalTokens)
			
			// Log the response
			resultJSON, _ := json.MarshalIndent(result, "", "  ")
			m.debugLog("Response: %s", string(resultJSON))
			
			// Log raw response if available
			if len(rawResponse.Choices) > 0 {
				m.debugLog("Raw Response Content: %s", rawResponse.Choices[0].Message.Content)
			}
		}
		m.debugLog("=== Translation Complete ===")
	}
	
	return result, err
}

// TranslationRaw executes the Translation goal and returns the raw OpenRouter response
func (m *Mango) TranslationRaw(input *TranslationInput) (*TranslationOutput, *openrouter.NonStreamingChatResponse, error) {
	return llmango.RunRaw[TranslationInput, TranslationOutput](m.LLMangoManager, translationGoal, input)
}

// TextSummary executes the Text Summary goal
func (m *Mango) TextSummary(input *SummaryInput) (*SummaryOutput, error) {
	if m.Debug {
		m.debugLog("=== TextSummary Request ===")
		inputJSON, _ := json.MarshalIndent(input, "", "  ")
		m.debugLog("Input: %s", string(inputJSON))
		
		// Log goal schema information
		m.debugLog("Goal: %s (%s)", "text-summary", "Text Summary")
		m.debugLog("Input Schema: %s", string(summaryGoal.InputExample))
		m.debugLog("Output Schema: %s", string(summaryGoal.OutputExample))
	}
	result, rawResponse, err := llmango.RunRaw[SummaryInput, SummaryOutput](m.LLMangoManager, summaryGoal, input)
	
	if m.Debug {
		if err != nil {
			m.debugLog("Error: %v", err)
		} else {
			// Log the raw response details
			m.debugLog("Model Used: %s", rawResponse.Model)
			m.debugLog("Usage - Prompt Tokens: %d, Completion Tokens: %d, Total: %d",
				rawResponse.Usage.PromptTokens, rawResponse.Usage.CompletionTokens, rawResponse.Usage.TotalTokens)
			
			// Log the response
			resultJSON, _ := json.MarshalIndent(result, "", "  ")
			m.debugLog("Response: %s", string(resultJSON))
			
			// Log raw response if available
			if len(rawResponse.Choices) > 0 {
				m.debugLog("Raw Response Content: %s", rawResponse.Choices[0].Message.Content)
			}
		}
		m.debugLog("=== TextSummary Complete ===")
	}
	
	return result, err
}

// TextSummaryRaw executes the Text Summary goal and returns the raw OpenRouter response
func (m *Mango) TextSummaryRaw(input *SummaryInput) (*SummaryOutput, *openrouter.NonStreamingChatResponse, error) {
	return llmango.RunRaw[SummaryInput, SummaryOutput](m.LLMangoManager, summaryGoal, input)
}
